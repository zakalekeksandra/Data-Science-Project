{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook tests various machine learning models based on previously pre-processed wine dataset and compare metrics to identify which classify wine quality most accurately."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import f1_score, accuracy_score, balanced_accuracy_score, cohen_kappa_score\n",
    "from imblearn.metrics import geometric_mean_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from plotly import graph_objects as go\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.pipeline import Pipeline as imbpipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Reading data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):                \n",
    "    directory = path + 'cleaned_wine_data.csv'\n",
    "    dataset = pd.read_csv(directory, index_col=[0])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Application:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.695163</td>\n",
       "      <td>-0.261684</td>\n",
       "      <td>0.144245</td>\n",
       "      <td>-0.766859</td>\n",
       "      <td>-0.208407</td>\n",
       "      <td>-0.900220</td>\n",
       "      <td>0.314921</td>\n",
       "      <td>-0.180598</td>\n",
       "      <td>0.472180</td>\n",
       "      <td>-0.288309</td>\n",
       "      <td>-0.885144</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.667890</td>\n",
       "      <td>-0.380575</td>\n",
       "      <td>0.552136</td>\n",
       "      <td>0.410863</td>\n",
       "      <td>-0.181305</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>-0.301474</td>\n",
       "      <td>0.189947</td>\n",
       "      <td>0.222398</td>\n",
       "      <td>-0.622007</td>\n",
       "      <td>-0.379421</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.013636</td>\n",
       "      <td>-0.677803</td>\n",
       "      <td>0.008281</td>\n",
       "      <td>0.766401</td>\n",
       "      <td>0.035512</td>\n",
       "      <td>0.951064</td>\n",
       "      <td>1.265929</td>\n",
       "      <td>0.358377</td>\n",
       "      <td>-0.214721</td>\n",
       "      <td>-0.888964</td>\n",
       "      <td>-0.547996</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.770888</td>\n",
       "      <td>-0.142793</td>\n",
       "      <td>-1.079428</td>\n",
       "      <td>0.433084</td>\n",
       "      <td>-0.316815</td>\n",
       "      <td>-0.002628</td>\n",
       "      <td>0.385366</td>\n",
       "      <td>0.122576</td>\n",
       "      <td>-0.277166</td>\n",
       "      <td>-0.421788</td>\n",
       "      <td>-0.800857</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>0.667890</td>\n",
       "      <td>-0.737249</td>\n",
       "      <td>0.756081</td>\n",
       "      <td>-0.789080</td>\n",
       "      <td>-0.343917</td>\n",
       "      <td>-0.114827</td>\n",
       "      <td>0.262087</td>\n",
       "      <td>-0.247970</td>\n",
       "      <td>-0.027384</td>\n",
       "      <td>-0.555267</td>\n",
       "      <td>0.379162</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "1     1      -0.695163         -0.261684     0.144245       -0.766859   \n",
       "2     1       0.667890         -0.380575     0.552136        0.410863   \n",
       "3     1      -0.013636         -0.677803     0.008281        0.766401   \n",
       "6     1      -0.770888         -0.142793    -1.079428        0.433084   \n",
       "9     1       0.667890         -0.737249     0.756081       -0.789080   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide   density        pH  \\\n",
       "1  -0.208407            -0.900220              0.314921 -0.180598  0.472180   \n",
       "2  -0.181305            -0.002628             -0.301474  0.189947  0.222398   \n",
       "3   0.035512             0.951064              1.265929  0.358377 -0.214721   \n",
       "6  -0.316815            -0.002628              0.385366  0.122576 -0.277166   \n",
       "9  -0.343917            -0.114827              0.262087 -0.247970 -0.027384   \n",
       "\n",
       "   sulphates   alcohol  quality  \n",
       "1  -0.288309 -0.885144        1  \n",
       "2  -0.622007 -0.379421        1  \n",
       "3  -0.888964 -0.547996        1  \n",
       "6  -0.421788 -0.800857        1  \n",
       "9  -0.555267  0.379162        1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_data = read_data('/Users/aleksandra/Desktop/Data-Science-Project-main/')\n",
    "wine_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine_data.drop(['quality'], axis=1)\n",
    "y = wine_data['quality']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Train-test split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Features selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check whether all our features are useful for training our model. We will use forests of trees to evaluate the importance of features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature ranking:\n",
      "1. feature 2 (0.104943)\n",
      "2. feature 6 (0.102563)\n",
      "3. feature 11 (0.091795)\n",
      "4. feature 10 (0.090428)\n",
      "5. feature 4 (0.088189)\n",
      "6. feature 3 (0.086759)\n",
      "7. feature 7 (0.086474)\n",
      "8. feature 9 (0.086010)\n",
      "9. feature 8 (0.085548)\n",
      "10. feature 1 (0.084852)\n",
      "11. feature 5 (0.083175)\n",
      "12. feature 0 (0.009263)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "forest = ExtraTreesClassifier(n_estimators=250,\n",
    "                              random_state=0)\n",
    "\n",
    "forest.fit(X_train, y_train)\n",
    "importances = forest.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in forest.estimators_],\n",
    "         axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %d (%f)\" % (f + 1, indices[f], importances[indices[f]]))\n",
    "\n",
    "# Plot the impurity-based feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "plt.bar(range(X_train.shape[1]), importances[indices],\n",
    "    color=\"r\", yerr=std[indices], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1]), indices)\n",
    "plt.xlim([-1, X_train.shape[1]])\n",
    "feature_names = X_train.columns\n",
    "plt.xticks(range(X_train.shape[1]), feature_names, rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use first 6 features with the highest importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4106, 6)\n",
      "(1027, 6)\n"
     ]
    }
   ],
   "source": [
    "model = SelectFromModel(forest, prefit=True, max_features=6)\n",
    "X_train = model.transform(X_train)\n",
    "X_test = model.transform(X_test)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-validation and metrics preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be checking our models for the dataset that is imbalanced (X_train, y_train) as well as balanced dataset (X_balanced, y_balanced)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of cross-validation is to test the model's ability to predict new data that was not used in estimating it, in order to flag problems like overfitting or selection bias and to give an insight on how the model will generalize to an independent dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=123, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also create dictionaries for adding all the metrics for each model. We will use 5 metrics for our dataset:\n",
    "\n",
    "- **f1 score** - is the harmonic mean between precision and recall, it tells how precise the classifier is and how robust it is \n",
    "\n",
    "- **acuracy score** - it is the ratio of number of correct predictions to the total number of input samples\n",
    "\n",
    "- **balanced accuracy score** - it is calculated as the average of the proportion corrects of each class individually\n",
    "\n",
    "- **cohen kappa score** - measures inter-rater agreement for qualitative (categorical) items.\n",
    "More: https://medium.com/x8-the-ai-community/kappa-coefficient-for-dummies-84d98b6f13ee\n",
    "\n",
    "- **geometric mean score** - measures the balance between classification performances on both the majority and minority classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "f1_scores = {}\n",
    "accuracy_scores = {}\n",
    "balanced_accuracy_scores = {}\n",
    "cohen_kappa_scores = {}\n",
    "geometric_mean_scores = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we will also define a function for calculating metrics and adding them to our dictionaries. This function takes classificator name and grid best estimator as arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_metrics(name, best_params):\n",
    "    print(name)\n",
    "\n",
    "    accuracy_scores[name] = accuracy_score(y_test, best_params.predict(X_test))\n",
    "    print(\"accuracy_score: {}\".format(accuracy_scores[name]))\n",
    "    \n",
    "    balanced_accuracy_scores[name] = balanced_accuracy_score(y_test, best_params.predict(X_test))\n",
    "    print(\"balanced_accuracy_score: {}\".format(balanced_accuracy_scores[name])) \n",
    "    \n",
    "    cohen_kappa_scores[name] = cohen_kappa_score(y_test, best_params.predict(X_test))\n",
    "    print(\"cohen_kappa_score: {}\".format(cohen_kappa_scores[name]))\n",
    "    \n",
    "    geometric_mean_scores[name] = geometric_mean_score(y_test, best_params.predict(X_test))\n",
    "    print(\"geometric_mean_score: {}\".format(geometric_mean_scores[name]))     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. KNN classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with K-Nearest Neighbor Classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 3, 'knn__weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "pipeline_1 = imbpipeline(steps = [['smote', SMOTE(random_state=0)],\n",
    "                                ['knn', KNeighborsClassifier()]])\n",
    "\n",
    "grid_params_1 = {\n",
    "            'knn__n_neighbors': [3,5,9,11],\n",
    "            'knn__weights' : ['uniform', 'distance'],\n",
    "                }\n",
    "\n",
    "grid_1 = GridSearchCV(\n",
    "                estimator=pipeline_1,\n",
    "                param_grid=grid_params_1,\n",
    "                cv=kfold\n",
    "                )\n",
    "\n",
    "grid_1.fit(X_train, y_train)\n",
    "print(grid_1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_balanced\n",
      "accuracy_score: 0.7409931840311588\n",
      "balanced_accuracy_score: 0.5459452682856938\n",
      "cohen_kappa_score: 0.1427271357919313\n",
      "geometric_mean_score: 0.5253886346735004\n"
     ]
    }
   ],
   "source": [
    "show_metrics('KNN_balanced', grid_1.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 11, 'weights': 'distance'}\n"
     ]
    }
   ],
   "source": [
    "grid_params_1_imbalanced = {\n",
    "            'n_neighbors': [3,5,9,11],\n",
    "            'weights' : ['uniform', 'distance'],\n",
    "                }\n",
    "\n",
    "grid_1_imbalanced = GridSearchCV(\n",
    "                estimator=KNeighborsClassifier(),\n",
    "                param_grid=grid_params_1_imbalanced,\n",
    "                cv=kfold\n",
    "                )\n",
    "\n",
    "grid_1_imbalanced.fit(X_train, y_train)\n",
    "print(grid_1_imbalanced.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN_imbalanced\n",
      "accuracy_score: 0.9152872444011685\n",
      "balanced_accuracy_score: 0.3333333333333333\n",
      "cohen_kappa_score: 0.0\n",
      "geometric_mean_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "show_metrics('KNN_imbalanced', grid_1_imbalanced.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we see from the above results we either get higher accuracy for imbalanced dataset and very low class balance or lower accuracy but better class balance for balanced dataset. Let's check other classificators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Decision Tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dtc__max_depth': 9, 'dtc__max_leaf_nodes': 30, 'dtc__min_samples_split': 2}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_2 = imbpipeline(steps = [['smote', SMOTE(random_state=0)],\n",
    "                                ['dtc', DecisionTreeClassifier()]])\n",
    "\n",
    "grid_params_2 = {\n",
    "            'dtc__max_depth': [5,9,10,11,20,30],\n",
    "            'dtc__min_samples_split': [2,3,5,10,20,30,40],\n",
    "            'dtc__max_leaf_nodes': [3,4,10,14,15,16,20,30,40]\n",
    "                }\n",
    "\n",
    "grid_2 = GridSearchCV(\n",
    "                estimator=pipeline_2,\n",
    "                param_grid=grid_params_2,\n",
    "                cv=kfold\n",
    "                )\n",
    "\n",
    "grid_2.fit(X_train, y_train)\n",
    "grid_2.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision_Tree_balanced\n",
      "accuracy_score: 0.5326192794547225\n",
      "balanced_accuracy_score: 0.5752310337416721\n",
      "cohen_kappa_score: 0.07702158971123219\n",
      "geometric_mean_score: 0.5690330331732459\n"
     ]
    }
   ],
   "source": [
    "show_metrics('Decision_Tree_balanced', grid_2.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 5, 'max_leaf_nodes': 3, 'min_samples_split': 2}\n",
      "Decision_Tree_imbalanced\n",
      "accuracy_score: 0.9152872444011685\n",
      "balanced_accuracy_score: 0.3333333333333333\n",
      "cohen_kappa_score: 0.0\n",
      "geometric_mean_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "grid_params_2_imbalanced = {\n",
    "            'max_depth': [5,9,10,11,20,30],\n",
    "            'min_samples_split': [2,3,5,10,20,30,40],\n",
    "            'max_leaf_nodes': [3,4,10,14,15,16,20,30,40]\n",
    "                }\n",
    "\n",
    "grid_2_imbalanced = GridSearchCV(\n",
    "                estimator=DecisionTreeClassifier(),\n",
    "                param_grid=grid_params_2_imbalanced,\n",
    "                cv=kfold\n",
    "                )\n",
    "\n",
    "grid_2_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "print(grid_2_imbalanced.best_params_)\n",
    "show_metrics('Decision_Tree_imbalanced', grid_2_imbalanced.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Random Forest "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.1 Balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rfc__bootstrap': False,\n",
       " 'rfc__max_depth': 50,\n",
       " 'rfc__max_features': 'auto',\n",
       " 'rfc__min_samples_leaf': 1,\n",
       " 'rfc__min_samples_split': 5}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_3 = imbpipeline(steps = [['smote', SMOTE(random_state=0)],\n",
    "                                ['rfc', RandomForestClassifier()]])\n",
    "\n",
    "grid_params_3 = {\n",
    "            'rfc__max_features': ['auto', 'sqrt'],\n",
    "            'rfc__min_samples_split': [2, 5, 10],\n",
    "            'rfc__min_samples_leaf': [1, 2, 4],\n",
    "            'rfc__bootstrap': [True, False],\n",
    "            'rfc__max_depth':[30,50]\n",
    "                }\n",
    "\n",
    "grid_3 = GridSearchCV(\n",
    "                    estimator=pipeline_3, \n",
    "                    param_grid=grid_params_3,\n",
    "                    cv=kfold\n",
    "                     )\n",
    "\n",
    "grid_3.fit(X_train, y_train)\n",
    "grid_3.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Forest_balanced\n",
      "accuracy_score: 0.8880233690360273\n",
      "balanced_accuracy_score: 0.4848687823865128\n",
      "cohen_kappa_score: 0.22331022872249473\n",
      "geometric_mean_score: 0.38822033376400605\n"
     ]
    }
   ],
   "source": [
    "show_metrics('Random_Forest_balanced', grid_3.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7.2 Imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': True, 'max_depth': 30, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "grid_params_3_imbalanced = {\n",
    "            'max_features': ['auto', 'sqrt'],\n",
    "            'min_samples_split': [2, 5, 10],\n",
    "            'min_samples_leaf': [1, 2, 4],\n",
    "            'bootstrap': [True, False],\n",
    "            'max_depth':[30,50]\n",
    "                }\n",
    "\n",
    "grid_3_imbalanced = GridSearchCV(\n",
    "                    estimator=RandomForestClassifier(), \n",
    "                    param_grid=grid_params_3_imbalanced,\n",
    "                    cv=kfold\n",
    "                     )\n",
    "\n",
    "grid_3_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "print(grid_3_imbalanced.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_Forest_imbalanced\n",
      "accuracy_score: 0.9152872444011685\n",
      "balanced_accuracy_score: 0.3507880220646178\n",
      "cohen_kappa_score: 0.056365249350484814\n",
      "geometric_mean_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "show_metrics('Random_Forest_imbalanced', grid_3_imbalanced.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Naive Bayes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 Balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sm = BorderlineSMOTE(sampling_strategy={0: 1000, 2: 1000},random_state=0)\n",
    "X_nb, y_nb = sm.fit_resample(X_train, y_train )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = GaussianNB()\n",
    "nb.fit(X_nb, y_nb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_Bayes_balanced\n",
      "accuracy_score: 0.7030185004868549\n",
      "balanced_accuracy_score: 0.5769193113164744\n",
      "cohen_kappa_score: 0.13719824594264052\n",
      "geometric_mean_score: 0.5671295086658846\n"
     ]
    }
   ],
   "source": [
    "show_metrics('Naive_Bayes_balanced', nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 Imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive_Bayes_imbalanced\n",
      "accuracy_score: 0.8977604673807206\n",
      "balanced_accuracy_score: 0.40840556868925665\n",
      "cohen_kappa_score: 0.17143691364380276\n",
      "geometric_mean_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "show_metrics('Naive_Bayes_imbalanced', nb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. SVM "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.1 Balanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'svc__C': 1, 'svc__gamma': 1}\n"
     ]
    }
   ],
   "source": [
    "pipeline_4 = imbpipeline(steps = [['smote', SMOTE(random_state=0)],\n",
    "                                ['svc', SVC(kernel='rbf')]])\n",
    "\n",
    "Cs = [0.01, 0.1 , 1]\n",
    "gammas = [0.01, 0.1, 1]\n",
    "\n",
    "grid_params_4 = {\n",
    "            'svc__C': Cs, \n",
    "            'svc__gamma' : gammas\n",
    "                }\n",
    "\n",
    "grid_4 = GridSearchCV(\n",
    "                estimator=pipeline_4,\n",
    "                param_grid=grid_params_4,\n",
    "                cv=kfold\n",
    "                )\n",
    "\n",
    "grid_4.fit(X_train, y_train)\n",
    "print(grid_4.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_balanced\n",
      "accuracy_score: 0.7546251217137293\n",
      "balanced_accuracy_score: 0.5276368889844067\n",
      "cohen_kappa_score: 0.13199624362758244\n",
      "geometric_mean_score: 0.49847903251922565\n"
     ]
    }
   ],
   "source": [
    "show_metrics('SVM_balanced',grid_4.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9.2 Imbalanced dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'gamma': 0.01}\n"
     ]
    }
   ],
   "source": [
    "Cs = [0.01, 0.1 , 1]\n",
    "gammas = [0.01, 0.1, 1]\n",
    "\n",
    "grid_params_4_imbalanced = {\n",
    "                        'C': Cs, \n",
    "                        'gamma' : gammas\n",
    "                            }\n",
    "\n",
    "grid_4_imbalanced = GridSearchCV(\n",
    "                estimator=SVC(kernel='rbf'),\n",
    "                param_grid=grid_params_4_imbalanced,\n",
    "                cv=kfold\n",
    "                )\n",
    "\n",
    "grid_4_imbalanced.fit(X_train, y_train)\n",
    "\n",
    "print(grid_4_imbalanced.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM_imbalanced\n",
      "accuracy_score: 0.9152872444011685\n",
      "balanced_accuracy_score: 0.3333333333333333\n",
      "cohen_kappa_score: 0.0\n",
      "geometric_mean_score: 0.0\n"
     ]
    }
   ],
   "source": [
    "show_metrics('SVM_imbalanced',grid_4_imbalanced.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py:610: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_validation.py\", line 593, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/imblearn/pipeline.py\", line 266, in fit\n",
      "    self._final_estimator.fit(Xt, yt, **fit_params_last_step)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_search.py:918: UserWarning: One or more of the test scores are non-finite: [0.43863272        nan 0.44179871        nan 0.44131031        nan\n",
      " 0.44179811        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'lr__C': 0.01, 'lr__penalty': 'l2'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_5 = imbpipeline(steps = [['smote', SMOTE(random_state=0)],\n",
    "                                ['lr', LogisticRegression(max_iter=1000)]])\n",
    "\n",
    "grid_params_5 = {'lr__C': [0.001, 0.01, 0.1, 1], \n",
    "                 'lr__penalty':['l2', 'l1']\n",
    "                }\n",
    "\n",
    "grid_5 = GridSearchCV(\n",
    "                estimator=pipeline_5,\n",
    "                param_grid=grid_params_5,\n",
    "                cv=kfold,\n",
    "                )\n",
    "\n",
    "grid_5.fit(X_train, y_train)\n",
    "grid_5.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic_Regression_balanced\n",
      "accuracy_score: 0.4488802336903603\n",
      "balanced_accuracy_score: 0.6554289944360866\n",
      "cohen_kappa_score: 0.0932599973793734\n",
      "geometric_mean_score: 0.630578691617203\n"
     ]
    }
   ],
   "source": [
    "show_metrics('Logistic_Regression_balanced',grid_5.best_estimator_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment: We can see that despite increasing total number of iterations algorithm could not converge to optimal parameters. Therefore we will not even try with imbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11.Final results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, let's see the results for each model in a form of a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy_score</th>\n",
       "      <th>balanced_accuracy_score</th>\n",
       "      <th>cohen_kappa_score</th>\n",
       "      <th>geometric_mean_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>KNN_balanced</th>\n",
       "      <td>0.740993</td>\n",
       "      <td>0.545945</td>\n",
       "      <td>0.142727</td>\n",
       "      <td>0.525389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNN_imbalanced</th>\n",
       "      <td>0.915287</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_Tree_balanced</th>\n",
       "      <td>0.532619</td>\n",
       "      <td>0.575231</td>\n",
       "      <td>0.077022</td>\n",
       "      <td>0.569033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision_Tree_imbalanced</th>\n",
       "      <td>0.915287</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_balanced</th>\n",
       "      <td>0.888023</td>\n",
       "      <td>0.484869</td>\n",
       "      <td>0.223310</td>\n",
       "      <td>0.388220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random_Forest_imbalanced</th>\n",
       "      <td>0.915287</td>\n",
       "      <td>0.350788</td>\n",
       "      <td>0.056365</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive_Bayes_balanced</th>\n",
       "      <td>0.703019</td>\n",
       "      <td>0.576919</td>\n",
       "      <td>0.137198</td>\n",
       "      <td>0.567130</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive_Bayes_imbalanced</th>\n",
       "      <td>0.897760</td>\n",
       "      <td>0.408406</td>\n",
       "      <td>0.171437</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_balanced</th>\n",
       "      <td>0.754625</td>\n",
       "      <td>0.527637</td>\n",
       "      <td>0.131996</td>\n",
       "      <td>0.498479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVM_imbalanced</th>\n",
       "      <td>0.915287</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Logistic_Regression_balanced</th>\n",
       "      <td>0.448880</td>\n",
       "      <td>0.655429</td>\n",
       "      <td>0.093260</td>\n",
       "      <td>0.630579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              accuracy_score  balanced_accuracy_score  \\\n",
       "KNN_balanced                        0.740993                 0.545945   \n",
       "KNN_imbalanced                      0.915287                 0.333333   \n",
       "Decision_Tree_balanced              0.532619                 0.575231   \n",
       "Decision_Tree_imbalanced            0.915287                 0.333333   \n",
       "Random_Forest_balanced              0.888023                 0.484869   \n",
       "Random_Forest_imbalanced            0.915287                 0.350788   \n",
       "Naive_Bayes_balanced                0.703019                 0.576919   \n",
       "Naive_Bayes_imbalanced              0.897760                 0.408406   \n",
       "SVM_balanced                        0.754625                 0.527637   \n",
       "SVM_imbalanced                      0.915287                 0.333333   \n",
       "Logistic_Regression_balanced        0.448880                 0.655429   \n",
       "\n",
       "                              cohen_kappa_score  geometric_mean_score  \n",
       "KNN_balanced                           0.142727              0.525389  \n",
       "KNN_imbalanced                         0.000000              0.000000  \n",
       "Decision_Tree_balanced                 0.077022              0.569033  \n",
       "Decision_Tree_imbalanced               0.000000              0.000000  \n",
       "Random_Forest_balanced                 0.223310              0.388220  \n",
       "Random_Forest_imbalanced               0.056365              0.000000  \n",
       "Naive_Bayes_balanced                   0.137198              0.567130  \n",
       "Naive_Bayes_imbalanced                 0.171437              0.000000  \n",
       "SVM_balanced                           0.131996              0.498479  \n",
       "SVM_imbalanced                         0.000000              0.000000  \n",
       "Logistic_Regression_balanced           0.093260              0.630579  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.DataFrame({'accuracy_score': pd.Series(accuracy_scores),\n",
    "                    'balanced_accuracy_score': pd.Series(balanced_accuracy_scores), \n",
    "                    'cohen_kappa_score':pd.Series(cohen_kappa_scores),\n",
    "                    'geometric_mean_score': pd.Series(geometric_mean_scores)},\n",
    "                    index=accuracy_scores.keys())\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at the above results we can see the trade-off between higher accuracy and correct class classfication. Dependent on client's end goal we would have chosen the right approach here. Without it, it is hard to say which model and approach (balanced or imbalanced) is better here.\n",
    "\n",
    "If we care more about accuracy we could chose between various models. However higher accuracy score does not necessarily mean better model here. We should also consider model's sensitivity to minority classes. In this case Naive Bayes balanced or Decision Tree balanced would be best here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use radial graph to present metrics for each model which allow us to see how gradually metrics decrease as we apply diffrent machine learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "mode": "lines",
         "name": "KNN_balanced",
         "r": [
          0.7409931840311588,
          0.5459452682856938,
          0.1427271357919313,
          0.5253886346735004,
          0.7409931840311588
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "KNN_imbalanced",
         "r": [
          0.9152872444011685,
          0.3333333333333333,
          0,
          0,
          0.9152872444011685
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Decision_Tree_balanced",
         "r": [
          0.5326192794547225,
          0.5752310337416721,
          0.07702158971123219,
          0.5690330331732459,
          0.5326192794547225
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Decision_Tree_imbalanced",
         "r": [
          0.9152872444011685,
          0.3333333333333333,
          0,
          0,
          0.9152872444011685
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Random_Forest_balanced",
         "r": [
          0.8880233690360273,
          0.4848687823865128,
          0.22331022872249473,
          0.38822033376400605,
          0.8880233690360273
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Random_Forest_imbalanced",
         "r": [
          0.9152872444011685,
          0.3507880220646178,
          0.056365249350484814,
          0,
          0.9152872444011685
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Naive_Bayes_balanced",
         "r": [
          0.7030185004868549,
          0.5769193113164744,
          0.13719824594264052,
          0.5671295086658846,
          0.7030185004868549
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Naive_Bayes_imbalanced",
         "r": [
          0.8977604673807206,
          0.40840556868925665,
          0.17143691364380276,
          0,
          0.8977604673807206
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "SVM_balanced",
         "r": [
          0.7546251217137293,
          0.5276368889844067,
          0.13199624362758244,
          0.49847903251922565,
          0.7546251217137293
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "SVM_imbalanced",
         "r": [
          0.9152872444011685,
          0.3333333333333333,
          0,
          0,
          0.9152872444011685
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        },
        {
         "mode": "lines",
         "name": "Logistic_Regression_balanced",
         "r": [
          0.4488802336903603,
          0.6554289944360866,
          0.0932599973793734,
          0.630578691617203,
          0.4488802336903603
         ],
         "theta": [
          "accuracy_score",
          "balanced_accuracy_score",
          "cohen_kappa_score",
          "geometric_mean_score",
          "accuracy_score"
         ],
         "type": "scatterpolar"
        }
       ],
       "layout": {
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        }
       }
      },
      "text/html": [
       "<div>                            <div id=\"c47fcaa4-17f5-481e-801e-62872bded759\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                require([\"plotly\"], function(Plotly) {                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"c47fcaa4-17f5-481e-801e-62872bded759\")) {                    Plotly.newPlot(                        \"c47fcaa4-17f5-481e-801e-62872bded759\",                        [{\"mode\": \"lines\", \"name\": \"KNN_balanced\", \"r\": [0.7409931840311588, 0.5459452682856938, 0.1427271357919313, 0.5253886346735004, 0.7409931840311588], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"KNN_imbalanced\", \"r\": [0.9152872444011685, 0.3333333333333333, 0.0, 0.0, 0.9152872444011685], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Decision_Tree_balanced\", \"r\": [0.5326192794547225, 0.5752310337416721, 0.07702158971123219, 0.5690330331732459, 0.5326192794547225], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Decision_Tree_imbalanced\", \"r\": [0.9152872444011685, 0.3333333333333333, 0.0, 0.0, 0.9152872444011685], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Random_Forest_balanced\", \"r\": [0.8880233690360273, 0.4848687823865128, 0.22331022872249473, 0.38822033376400605, 0.8880233690360273], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Random_Forest_imbalanced\", \"r\": [0.9152872444011685, 0.3507880220646178, 0.056365249350484814, 0.0, 0.9152872444011685], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Naive_Bayes_balanced\", \"r\": [0.7030185004868549, 0.5769193113164744, 0.13719824594264052, 0.5671295086658846, 0.7030185004868549], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Naive_Bayes_imbalanced\", \"r\": [0.8977604673807206, 0.40840556868925665, 0.17143691364380276, 0.0, 0.8977604673807206], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"SVM_balanced\", \"r\": [0.7546251217137293, 0.5276368889844067, 0.13199624362758244, 0.49847903251922565, 0.7546251217137293], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"SVM_imbalanced\", \"r\": [0.9152872444011685, 0.3333333333333333, 0.0, 0.0, 0.9152872444011685], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}, {\"mode\": \"lines\", \"name\": \"Logistic_Regression_balanced\", \"r\": [0.4488802336903603, 0.6554289944360866, 0.0932599973793734, 0.630578691617203, 0.4488802336903603], \"theta\": [\"accuracy_score\", \"balanced_accuracy_score\", \"cohen_kappa_score\", \"geometric_mean_score\", \"accuracy_score\"], \"type\": \"scatterpolar\"}],                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}},                        {\"responsive\": true}                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('c47fcaa4-17f5-481e-801e-62872bded759');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })                };                });            </script>        </div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = go.Figure()\n",
    "axis = data.columns.tolist()\n",
    "axis.append(axis[0])\n",
    "\n",
    "colors = {\n",
    "'KNN_balanced': '#1b9e77', \n",
    "'KNN_imbalanced': '#1b9e77',\n",
    "'Decision_Tree_balanced': '#d95f02',\n",
    "'Decision_Tree_imbalanced': '#d95f02',\n",
    "'Random_Forest_balanced': '#3446eb',\n",
    "'Random_Forest_imbalanced': '#3446eb',\n",
    "'Naive_Bayes_balanced': '#7570b3',\n",
    "'Naive_Bayes_imbalanced': '#7570b3',\n",
    "'SVM_balanced': '#9e6c1b',\n",
    "'SVM_imbalanced': '#9e6c1b',\n",
    "'Logistic_Regression_balanced': '#9e6c1b',\n",
    "} \n",
    "\n",
    "for (rowName, rowData) in data.iterrows():\n",
    "     plot_data = rowData.values.tolist()\n",
    "     plot_data.append(plot_data[0])\n",
    "\n",
    "     figure.add_trace(\n",
    "         go.Scatterpolar(\n",
    "         r=plot_data, \n",
    "         theta=axis, \n",
    "         mode='lines',\n",
    "         name=rowName))\n",
    "\n",
    "figure.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
